{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input CSV: ../data/NIST_database_onlyH_6TypeEq_pos_match_max_fg_other.csv\n",
      "Step 1: Averaging pKa values for each SMILES/Equilibrium pair...\n",
      "Averaged data shape: (3562, 3)\n",
      "Step 2: Aggregating averaged pKa values per SMILES...\n",
      "Aggregated pKa data shape: (1958, 2)\n",
      "Step 3: Getting max_eq_num for each SMILES...\n",
      "Step 4: Merging results...\n",
      "Final processed data shape: (1958, 3)\n",
      "Writing output CSV: ../data/processed_pka_data.csv\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# 格式： \n",
    "# SMILES,pKa_num, pKa_value\n",
    "# NCC(=O)O, 2, \"3,9\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_CSV_PATH = '../data/NIST_database_onlyH_6TypeEq_pos_match_max_fg_other.csv'\n",
    "OUTPUT_CSV_PATH = '../data/processed_pka_data.csv'\n",
    "OUTPUT_COLUMNS = ['SMILES', 'pKa_num', 'pKa_value']\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "def process_pka_data(input_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Reads the NIST pKa data, averages values for each equilibrium per SMILES,\n",
    "    and creates a new CSV with max_eq_num and sorted, comma-separated pKa values.\n",
    "    \"\"\"\n",
    "    print(f\"Reading input CSV: {input_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Validate required columns ---\n",
    "    required_cols = ['SMILES', 'Equilibrium', 'Value', 'max_eq_num']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Error: Input CSV missing one or more required columns: {required_cols}\")\n",
    "        return\n",
    "\n",
    "    # --- Data Cleaning (Optional but recommended) ---\n",
    "    # Convert 'Value' to numeric, coercing errors to NaN\n",
    "    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "    # Drop rows where averaging is impossible (missing SMILES or Value)\n",
    "    original_rows = len(df)\n",
    "    df.dropna(subset=['SMILES', 'Value'], inplace=True)\n",
    "    if len(df) < original_rows:\n",
    "        print(f\"Dropped {original_rows - len(df)} rows with missing SMILES or non-numeric Value.\")\n",
    "\n",
    "    print(\"Step 1: Averaging pKa values for each SMILES/Equilibrium pair...\")\n",
    "    # Group by SMILES and the specific equilibrium, then average the 'Value'\n",
    "    df_averaged = df.groupby(['SMILES', 'Equilibrium'], as_index=False)['Value'].mean()\n",
    "    print(f\"Averaged data shape: {df_averaged.shape}\")\n",
    "\n",
    "    print(\"Step 2: Aggregating averaged pKa values per SMILES...\")\n",
    "    # Group again just by SMILES to collect all averaged pKa values for that molecule\n",
    "    # Apply list to get all values, then apply sorting and formatting\n",
    "    def aggregate_pka(series):\n",
    "        # Sort numerically\n",
    "        sorted_pka = sorted(series.tolist())\n",
    "        # Format to string with 2 decimal places, separated by comma\n",
    "        return \",\".join([f\"{pka:.2f}\" for pka in sorted_pka])\n",
    "\n",
    "    df_aggregated_pka = df_averaged.groupby('SMILES')['Value'].apply(aggregate_pka).reset_index()\n",
    "    df_aggregated_pka.rename(columns={'Value': 'pKa_value'}, inplace=True)\n",
    "    print(f\"Aggregated pKa data shape: {df_aggregated_pka.shape}\")\n",
    "\n",
    "    print(\"Step 3: Getting max_eq_num for each SMILES...\")\n",
    "    # Get the max_eq_num (should be consistent per SMILES, take the first)\n",
    "    # Ensure max_eq_num is integer where possible\n",
    "    df_max_eq = df.groupby('SMILES', as_index=False)['max_eq_num'].first()\n",
    "    # Attempt conversion to integer, keeping floats if necessary (e.g., if NaNs existed)\n",
    "    try:\n",
    "        df_max_eq['max_eq_num'] = df_max_eq['max_eq_num'].astype(int)\n",
    "    except (ValueError, TypeError):\n",
    "        print(\"Warning: Could not convert all 'max_eq_num' values to integers.\")\n",
    "    df_max_eq.rename(columns={'max_eq_num': 'pKa_num'}, inplace=True)\n",
    "\n",
    "\n",
    "    print(\"Step 4: Merging results...\")\n",
    "    # Merge the aggregated pKa strings with the max_eq_num\n",
    "    df_final = pd.merge(df_max_eq, df_aggregated_pka, on='SMILES', how='inner')\n",
    "\n",
    "    # Ensure correct column order\n",
    "    df_final = df_final[OUTPUT_COLUMNS]\n",
    "    df_final = df_final.sort_values(by='pKa_num')\n",
    "    print(f\"Final processed data shape: {df_final.shape}\")\n",
    "\n",
    "    # --- Write Output ---\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        print(f\"Writing output CSV: {output_path}\")\n",
    "        df_final.to_csv(output_path, index=False) # quoting=3 for csv.QUOTE_NONE\n",
    "        print(\"Processing complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output CSV: {e}\")\n",
    "\n",
    "# --- Run the processing ---\n",
    "if __name__ == \"__main__\":\n",
    "    process_pka_data(INPUT_CSV_PATH, OUTPUT_CSV_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
